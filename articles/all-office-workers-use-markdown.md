---
title: "LLM を扱う全ての人間はマークダウン記法を習得しておくべき"
emoji: "📝"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["LLM", "Markdown"]
published: false
---

## 本記事で主張したいこと

- プロンプトは基本的に Markdown で記述すべきである
  - ただし、出力フォーマットを厳密に指定したいなど一部のケースでは、XML や YAML や JSON 等を用いる場合もある
- プログラマーに限らず大半のオフィスワーカーが LLM を活用する時代が来つつある
  - プログラマー以外の職種の人間も Markdown を習得すべき
- プロンプトだけでなく、ドキュメントも可能な範囲内で Markdown で記述した方が良い

## 理由

- インターネット上には Markdown のドキュメントが多数存在しており、LLM の学習データとして多く使われているため、LLM にとって Markdown は見知った形式である
- Markdown を用いることで、文章をある程度は構造化できる
  - 文章が構造化されていると、LLM は文章の内容を理解しやすいし、人間にとっても理解しやすい
- RAG でドキュメントを参照する際、Markdown のようなプレーンテキストは扱いやすい
  - プレーンテキストではないフォーマットを RAG で扱う場合、Markdown に変換する手間が発生する
    - その際、表などの一部の情報が欠落し、LLM が情報を適切に扱えなくなってしまう場合がある

## 参考にさせて頂いた書籍

### [LLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発](https://www.oreilly.co.jp/books/9784814401130/)

John Berryman, Albert Ziegler 著, 服部 佑樹、佐藤 直生 訳, 株式会社オーム社, 2025

66p, 67p
> まず第一の基準として、プロンプトはトレーニングセット中のドキュメントに近い形式であるべきです。
> これを「赤ずきんの原則」と呼びます。
> (中略)
> 「赤ずきんの原則」は本書で何度も登場しますが、今は「トレーニングデータで一般的なパターンを模倣すべき」という点を覚えておけば十分です。
> 幸いにも、参考にできるドキュメントやパターンは無数にあります。
> 補完モデルの場合、プロンプトをコンピュータプログラム、ニュース記事、ツイート、Markdownドキュメント、通信記録など、トレーニングデータにありそうな形式に寄せることができます。
> チャットモデルの場合は、全体のドキュメント形式はすでに決まっています（たとえばOpenAIでは、指示用のシステムメッセージが先頭にあり、その後ユーザーとアシスタントのやり取りが続くChatMLドキュメント）。
> しかし、その中でも「赤ずきんの原則」を活用し、ユーザーメッセージ内でMarkdown構文などを使って、モデルが理解しやすい構造を示すことができます。
> セクションを示すために#を使ったり、コードブロックのためにバッククォートで囲んだり、リスト項目として*を使ったりして、モデルにわかりやすい手がかりを与えるのです。

69p
![alt text](/images/all-office-workers-use-markdown/image.png)

> まず、このプロンプトが「赤ずきんの原則」に従っていることに注目してください。
> これは「宿題の課題」という形式で、トレーニングデータの中で頻繁に見られる種類のドキュメントです。
> また、このドキュメントはMarkdownという一般的なマークアップ言語で書かれています。
> これにより、セクションの見出しや太字・イタリック体などの構文を通じて、モデルに予測可能な方法でドキュメントを構造化するよう促すことができます。
> 最も基本的なレベルでは、適切な文法を使用することが重要です。
> 不適切な文法を使用すると、モデルも同様に雑な文体でテキストを生成してしまう傾向があるためです。
> このように、私たちは確実に「おばあさんの家」への正しい道筋をたどっているのです。
> 次に、LLMが問題を理解するために必要なコンテキストがプロンプトにどのように組み込まれているかを見てみましょう。
> このコンテキストがカギ括弧「」で示されています。
> まず最初に実際のユーザーの問題提起があります。
> おそらくユーザーは旅行ウェブサイトのドロップダウンメニューから誤って北朝鮮を選択してしまったのかもしれません。
> いずれにせよ、この選択内容が最初の太字のテキストスニペットとしてプロンプトに組み込まれています。
> その後に続く太字部分には、関連リソースから抽出した情報、具体的には国務省の渡航勧告や最近のニュース記事の見出しが含まれています。
> この例では、これらの情報があれば旅行に関する推奨事項を提示するのに十分です。
> このプロンプトには、問題を詳しく掘り下げるのではなく、明確な解決策へとモデルを導くための工夫がいくつか組み込まれています。
> まず冒頭で、レジャー・旅行・観光ドメインに関連するレスポンスを引き出すよう、モデルに対して条件付けをしています。
> そして次に例題を含めています。
> これは実際のユーザーからのリクエストとは無関係ですが、
> 「## 問題N」の形式で問題が提示され、それに対する解答が「## 解決策N」で続く、
> というパターンをモデルに認識させる役割を果たしています。
> 問題1は、その後続く回答を簡潔で礼儀正しいトーンに誘導します。
> 解決策1が短い文章で構成されているのは、このようなレスポンススタイルをモデルの出力でも継続させる意図があります。
> このパターンを確立した上で、解決策2で実際のユーザーの問題を提示します。
> ここでは問題設定とコンテキストを示した後、「顧客には何と言うべきでしょうか？」という具体的な問いかけを行います。
> そして「## 解決策2」という区切りを入れることで、問題文が終わり、今度は回答を出す段階であることを明確にします。
> もしこの区切りを省略してしまうと、モデルは北朝鮮に関する架空の情報を次々と作り出して問題の説明を延々と続けてしまうでしょう。
> 最後の重要なタスクは、回答をきっぱりと終了させることです。Markdownでは各セクションが「##」で始まるというパターンがあり、これを活用することができます。

126p
> レポートについては、1つの形式、つまりMarkdownでプロンプトを書くことを一貫して推奨します。
> 理由は次の通りです。
>
> - Markdownは普遍的で、インターネット上にMarkdownファイルが多数存在するため、LLMがよく知っている形式です。
> - Markdownはシンプルで軽量な記法です。機能が少ないので書きやすく、モデルがコンテンツを解釈しやすいという利点があります。
> - 見出しを使って階層構造を表現できるため、プロンプト要素を明確なセクションに分けやすく、不要な部分を外しても全体の構造を保つことができます。
> - インデントが基本的には問題にならず、ソースコードなど技術的な内容については```（バッククォート3つ）で囲んでブロック形式を利用すればOKです。
> - ユーザーにモデルのレスポンスを直接表示したい場合にもMarkdownは簡単にレンダリングできます。
> - Markdownのハイパーリンク機能を使えばモデルがリンクを含めた出力をしやすくなり、ソースの検証やコンテンツの再取得を自動化しやすくなります。
>
> さらに、Markdownファイルの冒頭に目次を付けるのが一般的で、これは非常に有用です。
> 目次は、人々と同様にモデルが方向性を把握するのに役立つため、長いプロンプトの導入部分として役立ちます。
> さらに、生成するテキストを制御する上でも有用です。

172p
> Markdownはトレーニングデータで頻繁に発生するモチーフであり、
> モデルはMarkdownが意味する構造を容易に理解します（これは、「あなた」が独自のプロンプトを整理するときにMarkdownを使用すべきだ、というヒントでもあります）。

175p
> 本節では、会話型エージェントに関連付けられたツールを設計、記述する際に従うべき、一般的なガイドラインを提供します。
> 主に、これらのガイドラインは、2つの直感に依存しています。
>
> 1. 人にとって理解しやすいものは何でも、LLMにとっても理解しやすいものです。
> 2. トレーニングデータに倣ってプロンプトをパターン化することで、最適な結果が導き出されます
> （別名「赤ずきんの原則」）。

246p
> 本書の主な教訓を要約すると、以下の2つになります。
>
> 1. LLMは学習時に見たテキストを模倣する、単なるテキスト補完エンジンにすぎません。
> 2. LLMに共感し、その思考方法を理解する必要があります。
> 最初の教訓について、本書の執筆を始めた時、私たちがアクセスできたのは補完モデルだけでした。
> これは、ドキュメントの一部（いわゆる「プロンプト」）を与えると、そのドキュメントを完成させる妥当なテキストを生成するものでした。
> しかしその後、チャットAPIが主流となり、次にツールが登場し、そしておそらく、アーティファクトが次の大きな革新となるでしょう。
> しかし、それでもなお、LLMの本質は、モデルが「好む」よう学習した他のドキュメントに似たドキュメントを完成させることにすぎません。
> ただし今では、そのドキュメントがチャットの記録のような形を取っているだけなのです。
> ここでのプロンプトエンジニアリングの教訓は、
> よく踏まれた道をたどること（「4章　LLMアプリケーションの設計」の赤ずきんの原則）です。
> プロンプトをトレーニングデータに見られるパターンやモチーフに従わせることで、扱いやすく予測可能な補完を得られる可能性が高くなります。
> たとえば、複雑なテキストをMarkdownとしてフォーマットしたり、LLMに伝える情報に標準的なドキュメント形式がある場合は、
> モデルが見たことのない新しい形式を考え出すよりも、その形式を使う方がうまくいくでしょう。

130p, 131p
> 構造化ドキュメントにもさまざまな形式があります。
> 「赤ずきんの原則」によれば、すでにトレーニングデータに多く含まれている形式を使うのが良いでしょう。
> 最も適切な形式はXMLとYAMLです。
> 両者とも精度が重要な技術ドキュメントでよく使用され、多岐にわたるドメインで利用できます。
> どちらの場合も、ドキュメント全体が通常名前付けされた要素に階層的に整理され、それぞれの要素は複数のサブ要素を持つことができます。
>
> XML（<https://oreil.ly/NvPU4>） では、ドキュメントは開始タグと終了タグのペアで構成されます。
> タグは属性を持つことができ、サブタグを含むコンテンツを持ちます。
> 個々の要素が比較的短く、複数行の場合でもインデントが重要でない場合はXMLを選択してください。
> ただし、XMLには5つのエスケープシーケンス（&quot（"）、&apos（'）、&lt（<）、&gt（>）、&amp（&））があるため、注意が必要です。
> XMLではHTML形式のコメントも追加でき、モデルに対するちょっとした「編集上の注記」を仕込むときに便利です。
>
> YAML（<https://yaml.org>）では、ドキュメントは名前付きフィールドまたは名前のない箇条書きで構成され、階層レベルはインデントによって管理されます。>
> このインデント管理は標準パーサーを使用するために正確に設定する必要があるため少々面倒ですが、コードや整形されたテキストなど、インデントを非常に正確に指定する必要がある場合に役立ちます。
> 特に、fieldname: |2という構文は、図6-4に示すように、インデントを保持する複数行のテキストフィールドを開きます。
> このようなテキストフィールドではエスケープが不要なため、扱いやすいという利点があります。
>
> JSONやその派生形式であるJSON Linesも、LLMのトレーニングセットで重要な役割を果たすべきマークアップ言語です。
> 以前は、JSONはエスケープが多く可読性が低いため推奨していませんでした。
> しかし、特にOpenAIは、ツールAPIでJSONを使用しているため、モデルが正確にJSONを生成できるよう多大な努力を払っています。
> そのため、少なくともOpenAIに関しては、JSONは依然として妥当な選択肢となっています。
